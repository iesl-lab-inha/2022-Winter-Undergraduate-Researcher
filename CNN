from PIL import Image
import os, glob, numpy as np
import os
from sklearn.model_selection import train_test_split
import os, glob, numpy as np
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from keras.callbacks import EarlyStopping, ModelCheckpoint
import matplotlib.pyplot as plt
import keras.backend.tensorflow_backend as K
from keras.preprocessing.image import img_to_array, load_img, array_to_img
import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
def IDG(fname): #파일이름을 변수로 받는 ImageDataGenerator함수
   ImageDG = ImageDataGenerator(    rescale = 1. / 255,
                                     rotation_range=15, # 무작위 회전의 각도 범위
                                     width_shift_range=0.1, # 수평방향 범위내 이미지 이동
                                     height_shift_range = 0.1, # 수직방향 범위내 이미지 이동
                                     horizontal_flip=True, # 무작위 가로뒤집기
                                      zoom_range = 0.1,   # 무작위 확대/축소 범위
                                     fill_mode='nearest') # 인풋 경계의 바깥공간 채우는 방식
    img = tf.keras.preprocessing.image.load_img(fname) # 이미지파일로 변환
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)
    i=0
    save = fname.split('/')[0] + "/" + fname.split('/')[1]+ "/" + fname.split('/')[2] + "/" + fname.split('/')[3] # 생성된 파일 저장경로
   for batch in ImageDG.flow(x, batch_size=1, save_to_dir = save, save_prefix='new'+str(file_name_freq),
                                      save_format='jpg'):
       i+=1
       if i>7: # 새로 생성되는 데이터 개수 정해주기
           break
folder_list = os.listdir('./archive/data/train')
fname =  "./archive/data/train/"
for f in folder_list:
    fname =  "./archive/data/train/" + f+"/"
    file_list = os.listdir(fname)
    for i in file_list:
        filename = fname + i
        IDG(filename)
img_dir =  "./archive/data/train/"
categories = os.listdir(img_dir) 
num_classes = len(categories)
 
image_w = 64  
image_h = 64
 
pixel=  image_w * image_h * 3 
X=[]
y=[]
 
for idx, cat in enumerate(categories): 
    img_dir_detail = img_dir + '/' + cat
    files = glob.glob(img_dir_detail + "/*.jpg")
    for i,f in enumerate(files):
        try:
            img = Image.open(f)
            img = img.convert('RGB')
            img = img.resize((image_w,image_h)) 
            data = np.asarray(img)
            X.append(data)
            y.append(idx)
            if i % 300 == 0 : 
                print(cat, " : ", f)
        except:
            print(cat,str(i)," 번째에서 에러")
            
X = np.array(X)  
y = np.array(y)  

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3) 
X_train = X_train.astype(float) / 255.0 
X_test = X_test.astype(float) / 255.0
 
from keras.utils import to_categorical

y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
image_w = 64
image_h = 64
 
with K.tf_ops.device('/device:CPU:0'): #가동할 GPU가 없어 CPU로 설정
    model = Sequential() 
  
    
    model.add(Conv2D(32, (3,3), padding="same", input_shape=X_train.shape[1:], activation="relu")) 
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Dropout(0.25)) 
              
    model.add(Conv2D(64, (3,3), padding="same", activation="relu"))
    model.add(MaxPooling2D(pool_size=(2,2)))
    model.add(Dropout(0.25))
    
    #FC layer
    model.add(Flatten())
    model.add(Dense(256, activation = 'relu'))
    model.add(Dropout(0.5))
    model.add(Dense(num_classes, activation = 'softmax'))
    
             
    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam',metrics=['accuracy'])
    
    model_dir = './model'
    model_path = model_dir + "/cloud_classify.model"
    # 모델결과 저장 및 earlystopping
    checkpoint = ModelCheckpoint(filepath = model_path, monitor='val_loss', verbose = 1, save_best_only = True)
    early_stopping = EarlyStopping(monitor = 'val_loss', patience = 6)
from keras.models import load_model
 
path = './archive/data/test/'
category = os.listdir('./archive/data/train')
 
image_w = 64
image_h = 64
 
pixels = image_h * image_w * 3
 
X = []
filenames = []
files = glob.glob(path+"/*.*")
for f in files:
    img = Image.open(f)
    img = img.convert("RGB")
    img = img.resize((image_w, image_h))
    data = np.asarray(img)
    filenames.append(f)
    X.append(data)
 
X = np.array(X)
prediction_test = model.predict(X)
 
file_index = 0
for i in prediction_test:
    label = i.argmax() # [0.000, 0.000, 0.000, ..., 0.000, 1.000, 0.000] 중 최대값 추출 즉,1값의 인덱스
    print("////////////////////")
    print( filenames[file_index].split('\\')[-1] + "의 예측되는 구름종류 : " + category[label])
    file_index  = file_index+1
